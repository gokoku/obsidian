#raspberry_pi 

2021-11-22

# 遠野AI 開発の過程
---

AI 開発の経緯をまとめましたので、AI キャラが現在の形になったことをご理解頂けれは幸いです。

## 出発点

* AI ってどうやって作るのか?
* 何が出来て何が出来ないのか?
* よくわからない。
* とりあえず「AI」を使ってなんか面白いものを作ることにしよう!

## AI 検証開始

* AI のライブラリで出来る事を検証した。
* 素のライプラリで出来ることはあまり無いようだった。


* 物体検知は結局、人感センサー程度にしかならなかった。
* 分類アルゴリズムを使うと、カメラに映るものが色々に分類されるので、少しは面白味があると思いこれを採用した。


## キャラ素材からの落とし込み

* キャラクターは予め作成された動画でクオリティは高いが、パターンが決まっている。
* 柔軟に対応出来るためには、動的に変わる文章を読み上げる別なものが必要。
* 主キャラとチビキャラに分けて、主キャラは動画を順番に切り替えて使い、チビキャラはその場で音声合成を使ってテキストを読ませることにした。

## AI とキャラを組み合わせる

* 主キャラとチビキャラの動きを組み合わせることでパターンを作ることにした。
* パターンのバリエーションは、順番と組み合わせで増やした。
* AI の分類による値と、コンテンツの種類を紐付けた。
* こうすることで、カメラに映ったものを AI が何かと分類することで、コンテンツが切り替わるようになった。


## もう少し面白くしたい

* チビキャラがテキストを音声合成を使ってその場で喋れるので、時間がきたらその時の天気予報とニュースを Web から引っ張ってきて読ませるようにした。


# AIキャラのパターン表

![[Pasted image 20211122143709.png]]

このパターンをカメラでAIが分類したもので、切り替える仕組みになっています。

試してみて反応が良さげなもので分類してます、AI が何故それに分類するのかはわかりません。

![[Pasted image 20211130100927.png]]